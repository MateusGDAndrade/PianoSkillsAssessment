# PianoSkillsAssessment


Este repositÃ³rio contÃ©m a implementaÃ§Ã£o de um pipeline multimodal para avaliaÃ§Ã£o de habilidades de pianistas, baseado no *Multimodal PISA Dataset* (Papers with Code). Para esta primeira etapa do projeto, o objetivo Ã© processar sinais de Ã¡udio, extrair espectrogramas, e treinar modelos de rede neural unimodais para classificar o nÃ­vel de habilidade do pianista. Para a prÃ³xima entrega, serÃ¡ feito o treinamento de modelos de rede neural multimodais incluindo, dessa vez, os frames dos vÃ­deos para a classificaÃ§Ã£o o nÃ­vel de habilidade do pianista. Por fim, o desempenho de ambas as abordagens serÃ£o comparados por meio das anotaÃ§Ãµes das amostras. 

---
## Integrantes
Lucas Vizzotto de Castro 
Diego Cabral Morales 
Vitor Okubo
Jean Michel Furtado M'Peko 
Gabriela Barros 
Mateus Gentil Dantas de Andrade 
Pedro Henrique GonÃ§alez Moracci 

## ğŸ” VisÃ£o Geral do Projeto

1. **Dataset**: Multimodal PISA Dataset (Ã¡udioâ€¯+â€¯vÃ­deo) disponÃ­vel em [https://paperswithcode.com/dataset/multimodal-pisa](https://paperswithcode.com/dataset/multimodal-pisa)
2. **Modalidade Principal**: Ãudio (melspectrogramas)
3. **Fluxo**:

   * PrÃ©-processamento bruto de Ã¡udio em arquivos `.pt`
   * GeraÃ§Ã£o de espectrogramas em `.png` para anÃ¡lise visual
   * DataLoader multimodal para conversÃ£o em tensores prontos para treino
   * Dataset simplificado que carrega diretamente arquivos prÃ©-processados
   * Treinamento e avaliaÃ§Ã£o de rede neural

---

## ğŸ“¦ Estrutura de DiretÃ³rios

```
PianoSkillsAssessment/
â”œâ”€â”€ audio_samples/             # Arquivos .wav originais
â”œâ”€â”€ annotations/               # AnotaÃ§Ãµes multimodais em .pkl
â”œâ”€â”€ processed_data/            # Dados prÃ©-processados em .pt (treinamento e teste)
â”œâ”€â”€ preprocess.py              # Extrai Ã¡udio e salva .pt
â”œâ”€â”€ dataloader_multimodal.py   # DataLoader multimodal, disponibilizado pelos autores do artigo
â”œâ”€â”€ preprocessed_dataset.py    # Classe do Dataset com dados prÃ©-processados
â”œâ”€â”€ opts.py                    # ConfiguraÃ§Ãµes globais (caminhos, seeds, dims)
â”œâ”€â”€ t1_redes_neurais.ipynb     # Experimentos de treino e avaliaÃ§Ã£o
â””â”€â”€ README.md                  # DocumentaÃ§Ã£o do projeto
```


## âš™ï¸ ConfiguraÃ§Ã£o

1. **Defina os caminhos** em `opts.py`:

   * `dataset_audio_dir`: local dos arquivos `.wav`
   * `anno_r2u_dir`: diretÃ³rio com arquivos `.pkl` de anotaÃ§Ãµes
2. **Escolha a semente** (`random_seed`) e parÃ¢metros de amostragem:

   * `nclips`, `clip_len`, dimensÃµes de imagem (`audio_img_C/H/W`)

---

## ğŸ”„ PrÃ©-processamento

### preprocess.py

* Carrega o dataset em modo `test` e `train` via `VideoDataset` (classe do Data Loader multimodal)
* Itera com `DataLoader(batch_size=1)`
* Salva cada amostra (Ã¡udio + label) em `processed_data/test/sample_{i}.pt`

---

## ğŸ“š Data Loaders

### dataloader\_multimodal.py

* Classe `VideoDataset(Dataset)`:

  * LÃª anotaÃ§Ãµes em `.pkl` (Ã¡udio + frames de vÃ­deo)
  * Converte segmentos de Ã¡udio em melspectrogramas (`librosa`)
  * Normaliza e converte em tensor 1Ã—224Ã—224

### preprocessed\_dataset.py

* Classe `PreprocessedDataset(Dataset)`:

  * Carrega arquivos `.pt` gerados por `preprocess.py`
  * RÃ¡pido carregamento para treino/validaÃ§Ã£o

Uso no script ou notebook:

```python
from preprocessed_dataset import PreprocessedDataset
from torch.utils.data import DataLoader
train_dataset = PreprocessedDataset("./processed_data/train")
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
```