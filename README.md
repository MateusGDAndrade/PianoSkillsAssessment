# PianoSkillsAssessment


Este repositÃ³rio contÃ©m a implementaÃ§Ã£o de um pipeline multimodal para avaliaÃ§Ã£o de habilidades de pianistas, baseado no *Multimodal PISA Dataset* (Papers with Code). Para esta primeira etapa do projeto, o objetivo Ã© processar sinais de Ã¡udio, extrair espectrogramas, e treinar modelos de rede neural unimodais para classificar o nÃ­vel de habilidade do pianista. Para a prÃ³xima entrega, serÃ¡ feito o treinamento de modelos de rede neural multimodais incluindo agora os frames dos vÃ­deos para a classificaÃ§Ã£o o nÃ­vel de habilidade do pianista. Por fim, o desempenho de ambas as abordagens serÃ£o comparados por meio das anoteÃ§Ãµes das amostras. 

---
## Integrantes
Lucas Vizzotto de Castro 
Diego Cabral Morales 
Vitor
Jean Michel Furtado M'Peko 
Gabriela Barros 
Mateus Gentil Dantas de Andrade 
Pedro Henrique GonÃ§alez Moracci 

## ğŸ” VisÃ£o Geral do Projeto

1. **Dataset**: Multimodal PISA Dataset (Ã¡udioâ€¯+â€¯vÃ­deo) disponÃ­vel em [https://paperswithcode.com/dataset/multimodal-pisa](https://paperswithcode.com/dataset/multimodal-pisa)
2. **Modalidade Principal**: Ãudio (melspectrogramas)
3. **Fluxo**:

   * PrÃ©-processamento bruto de Ã¡udio em arquivos `.pt`
   * GeraÃ§Ã£o de espectrogramas em `.png` para anÃ¡lise visual
   * DataLoader multimodal para conversÃ£o em tensores prontos para treino
   * Dataset simplificado que carrega diretamente arquivos prÃ©-processados
   * Treinamento e avaliaÃ§Ã£o de rede neural 

---

## ğŸ“¦ Estrutura de DiretÃ³rios

```
PianoSkillsAssessment/
â”œâ”€â”€ audio_samples/             # Arquivos .wav originais
â”œâ”€â”€ annotations/               # AnotaÃ§Ãµes multimodais em .pkl
â”œâ”€â”€ processed_data/            # Dados prÃ©-processados em .pt (test)
â”œâ”€â”€ preprocessed_audio_samples/# Imagens .png dos espectrogramas
â”œâ”€â”€ PreProcess.py              # Extrai Ã¡udio e salva .pt
â”œâ”€â”€ PreProcess2.py             # Gera e salva espectrogramas .png
â”œâ”€â”€ dataloader_multimodal.py   # DataLoader multimodal
â”œâ”€â”€ preprocessed_dataset.py    # Dataset rÃ¡pido de arquivos .pt
â”œâ”€â”€ opts.py                    # ConfiguraÃ§Ãµes globais (caminhos, seeds, dims)
â””â”€â”€ README.md                  # DocumentaÃ§Ã£o do projeto
```


## âš™ï¸ ConfiguraÃ§Ã£o

1. **Defina os caminhos** em `opts.py`:

   * `dataset_audio_dir`: local dos arquivos `.wav`
   * `anno_r2u_dir`: diretÃ³rio com arquivos `.pkl` de anotaÃ§Ãµes
2. **Escolha a semente** (`random_seed`) e parÃ¢metros de amostragem:

   * `nclips`, `clip_len`, dimensÃµes de imagem (`audio_img_C/H/W`)

---

## ğŸ”„ PrÃ©-processamento

### 1. PreProcess.py

* Carrega o dataset em modo `test` via `VideoDataset`
* Itera com `DataLoader(batch_size=1)`
* Salva cada amostra (Ã¡udio + label) em `processed_data/test/sample_{i}.pt`

### 2. PreProcess2.py

* LÃª arquivos `.wav` de `audio_samples/`
* Gera espectrogramas via `scipy.signal.spectrogram`
* Converte para escala logarÃ­tmica, normaliza, salva como imagem `.png`
* Armazena em `preprocessed_audio_samples/`


---

## ğŸ“š Data Loaders

### dataloader\_multimodal.py

* Classe `VideoDataset(Dataset)`:

  * LÃª anotaÃ§Ãµes em `.pkl` (Ã¡udio + frames de vÃ­deo)
  * Converte segmentos de Ã¡udio em melspectrogramas (`librosa`)
  * Normaliza e converte em tensor 1Ã—224Ã—224

### preprocessed\_dataset.py

* Classe `PreprocessedDataset(Dataset)`:

  * Carrega arquivos `.pt` gerados por `PreProcess.py`

# PianoSkillsAssessment

Este repositÃ³rio contÃ©m a implementaÃ§Ã£o de um pipeline multimodal para avaliaÃ§Ã£o de habilidades pianÃ­sticas, baseado no *Multimodal PISA Dataset* (Papers with Code). O objetivo Ã© processar sinais de Ã¡udio (e potencialmente vÃ­deo), extrair espectrogramas, e treinar modelos de rede neural para classificar o nÃ­vel de habilidade do pianista.

---

## ğŸ” VisÃ£o Geral do Projeto

1. **Dataset**: Multimodal PISA Dataset (Ã¡udioâ€¯+â€¯vÃ­deo) disponÃ­vel em [https://paperswithcode.com/dataset/multimodal-pisa](https://paperswithcode.com/dataset/multimodal-pisa)
2. **Modalidade Principal**: Ãudio (melspectrogramas)
3. **Fluxo**:

   * PrÃ©-processamento bruto de Ã¡udio em arquivos `.pt`
   * GeraÃ§Ã£o de espectrogramas em `.png` para anÃ¡lise visual
   * DataLoader multimodal para conversÃ£o em tensores prontos para treino
   * Dataset simplificado que carrega diretamente arquivos prÃ©-processados
   * Treinamento e avaliaÃ§Ã£o de rede neural via Jupyter Notebook (`t1_redes_neurais.ipynb`) e script `train.py`

---

## ğŸ“¦ Estrutura de DiretÃ³rios

```
PianoSkillsAssessment/
â”œâ”€â”€ audio_samples/               # Arquivos .wav originais
â”œâ”€â”€ annotations/                 # AnotaÃ§Ãµes multimodais em .pkl
â”œâ”€â”€ processed_data/              # Dados prÃ©-processados em .pt (test)
â”œâ”€â”€ preprocessed_audio_samples/  # Imagens .png dos espectrogramas
â”œâ”€â”€ notebooks/                   # Notebooks de anÃ¡lise e experimentos
â”‚   â””â”€â”€ t1_redes_neurais.ipynb   # Experimentos de treino e avaliaÃ§Ã£o
â”œâ”€â”€ PreProcess.py                # Extrai Ã¡udio e salva .pt
â”œâ”€â”€ PreProcess2.py               # Gera e salva espectrogramas .png
â”œâ”€â”€ dataloader_multimodal.py     # DataLoader customizado multimodal
â”œâ”€â”€ preprocessed_dataset.py      # Dataset rÃ¡pido de arquivos .pt
â”œâ”€â”€ opts.py                      # ConfiguraÃ§Ãµes globais (caminhos, seeds, dims)
â”œâ”€â”€ train.py                     # Pipeline de treino e avaliaÃ§Ã£o (script)
â”œâ”€â”€ requirements.txt             # DependÃªncias do projeto
â””â”€â”€ README.md                    # DocumentaÃ§Ã£o do projeto
```

---

## ğŸ› ï¸ Requisitos

* Python 3.8 ou superior
* Bibliotecas:

  * `torch`, `torchvision`
  * `numpy`, `scipy`, `librosa`
  * `Pillow`, `pandas`
  * `jupyter`, `matplotlib` para visualizaÃ§Ã£o

Instale com:

```bash
pip install -r requirements.txt
```

---

## âš™ï¸ ConfiguraÃ§Ã£o

1. **Defina os caminhos** em `opts.py`:

   * `dataset_audio_dir`: local dos arquivos `.wav`
   * `anno_r2u_dir`: diretÃ³rio com arquivos `.pkl` de anotaÃ§Ãµes
2. **Escolha a semente** (`random_seed`) e parÃ¢metros de amostragem:

   * `nclips`, `clip_len`, dimensÃµes de imagem (`audio_img_C/H/W`)

---

## ğŸ”„ PrÃ©-processamento

### 1. PreProcess.py

* Carrega o dataset em modo `test` via `VideoDataset`
* Itera com `DataLoader(batch_size=1)`
* Salva cada amostra (Ã¡udio + label) em `processed_data/test/sample_{i}.pt`

Comando:

```bash
python PreProcess.py
```

### 2. PreProcess2.py

* LÃª arquivos `.wav` de `audio_samples/`
* Gera espectrogramas via `scipy.signal.spectrogram`
* Converte para escala logarÃ­tmica, normaliza, salva como imagem `.png`
* Armazena em `preprocessed_audio_samples/`

Comando:

```bash
python PreProcess2.py
```

---

## ğŸ“š Data Loaders

### dataloader\_multimodal.py

* Classe `VideoDataset(Dataset)`:

  * LÃª anotaÃ§Ãµes em `.pkl` (Ã¡udio + frames de vÃ­deo)
  * Converte segmentos de Ã¡udio em melspectrogramas (`librosa`)
  * Normaliza e converte em tensor 1Ã—224Ã—224

### preprocessed\_dataset.py

* Classe `PreprocessedDataset(Dataset)`:

  * Carrega arquivos `.pt` gerados por `PreProcess.py`
  * RÃ¡pido carregamento para treino/validaÃ§Ã£o

Uso no script ou notebook:

```python
from preprocessed_dataset import PreprocessedDataset
from torch.utils.data import DataLoader
train_dataset = PreprocessedDataset("./processed_data/train")
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
```

---

## ğŸ““ Notebook `t1_redes_neurais.ipynb`

Este notebook reÃºne:

1. **ExploraÃ§Ã£o de Dados**:

   * VisualizaÃ§Ã£o de espectrogramas
   * AnÃ¡lise de distribuiÃ§Ã£o de labels (nÃ­veis de habilidade)
2. **DefiniÃ§Ã£o de Modelo**:

   * Arquitetura CNN simples aplicada a espectrogramas
   * CritÃ©rio de perda e otimizador configurados via `opts.py`
3. **Loop de Treino e ValidaÃ§Ã£o**:

   * FunÃ§Ãµes para treino por Ã©poca e avaliaÃ§Ã£o em conjunto de validaÃ§Ã£o
   * Registro de mÃ©tricas (loss, acurÃ¡cia) e geraÃ§Ã£o de grÃ¡ficos
4. **Teste e Resultados**:

   * PrediÃ§Ãµes finais sobre conjunto de teste
   * Matriz de confusÃ£o e relatÃ³rio de classificaÃ§Ã£o
5. **Salvamento de Checkpoints**:

   * Arquivos `.pt` com pesos do modelo em `./checkpoints/`

